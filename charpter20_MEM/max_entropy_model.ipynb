{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大信息熵模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有问题没解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class MaxEnt:\n",
    "    def __init__(self, max_iter=100):\n",
    "        # 训练输入\n",
    "        self.X_ = None\n",
    "        # 训练标签\n",
    "        self.y_ = None\n",
    "        # 标签类别数量\n",
    "        self.m = None   \n",
    "        # 特征数量\n",
    "        self.n = None   \n",
    "        # 训练样本量\n",
    "        self.N = None   \n",
    "        # 常数特征取值\n",
    "        self.M = None\n",
    "        # 权重系数\n",
    "        self.w = None\n",
    "        # 标签名称\n",
    "        self.labels = defaultdict(int)\n",
    "        # 特征名称\n",
    "        self.features = defaultdict(int)\n",
    "        # 最大迭代次数\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    ### 计算特征函数关于经验联合分布P(X,Y)的期望\n",
    "    def _EP_hat_f(self, x, y):\n",
    "        self.Pxy = np.zeros((self.m, self.n))\n",
    "        self.Px = np.zeros(self.n)\n",
    "        for x_, y_ in zip(x, y):\n",
    "            # 遍历每个样本\n",
    "            for x__ in set(x_):\n",
    "                self.Pxy[self.labels[y_], self.features[x__]] += 1\n",
    "                self.Px[self.features[x__]] += 1           \n",
    "        self.EP_hat_f = self.Pxy/self.N\n",
    "    \n",
    "    ### 计算特征函数关于模型P(Y|X)与经验分布P(X)的期望\n",
    "    def _EP_f(self):\n",
    "        # self.EPf = np.zeros((self.m, self.n))\n",
    "        self.EP_f = np.zeros((self.m, self.n))\n",
    "        for X in self.X_:\n",
    "            pw = self._pw(X)\n",
    "            pw = pw.reshape(self.m, 1)\n",
    "            px = self.Px.reshape(1, self.n)\n",
    "            self.EP_f += pw*px / self.N\n",
    "    \n",
    "    ### 最大熵模型P(y|x)\n",
    "    def _pw(self, x):\n",
    "        mask = np.zeros(self.n+1)\n",
    "        for ix in x:\n",
    "            mask[self.features[ix]] = 1\n",
    "        tmp = self.w * mask[1:]\n",
    "        pw = np.exp(np.sum(tmp, axis=1))\n",
    "        Z = np.sum(pw)\n",
    "        pw = pw/Z\n",
    "        return pw\n",
    "\n",
    "    ### 熵模型拟合\n",
    "    ### 基于改进的迭代尺度方法IIS\n",
    "    def fit(self, x, y):\n",
    "        # 训练输入\n",
    "        self.X_ = x\n",
    "        # 训练输出\n",
    "        self.y_ = list(set(y))\n",
    "        # 输入数据展平后集合\n",
    "        tmp = set(self.X_.flatten())\n",
    "        # 特征命名\n",
    "        self.features = defaultdict(int, zip(tmp, range(1, len(tmp)+1)))   \n",
    "        # 标签命名\n",
    "        self.labels = dict(zip(self.y_, range(len(self.y_))))\n",
    "        # 特征数\n",
    "        self.n = len(self.features)+1  \n",
    "        # 标签类别数量\n",
    "        self.m = len(self.labels)\n",
    "        # 训练样本量\n",
    "        self.N = len(x)  \n",
    "        # 计算EP_hat_f\n",
    "        self._EP_hat_f(x, y)\n",
    "        # 初始化系数矩阵\n",
    "        self.w = np.zeros((self.m, self.n))\n",
    "        # 循环迭代\n",
    "        i = 0\n",
    "        while i <= self.max_iter:\n",
    "            # 计算EPf\n",
    "            self._EP_f()\n",
    "            # self.EP_f()\n",
    "            # 令常数特征函数为M\n",
    "            self.M = 100\n",
    "            # IIS算法步骤(3)\n",
    "            # tmp = np.true_divide(self.EP_hat_f, self.EP_f)\n",
    "            tmp = np.true_divide(self.EP_hat_f, self._EP_f)\n",
    "            tmp[tmp == np.inf] = 0\n",
    "            tmp = np.nan_to_num(tmp)\n",
    "            sigma = np.where(tmp != 0, 1/self.M*np.log(tmp), 0)  \n",
    "            # 更新系数:IIS步骤(4)\n",
    "            self.w = self.w + sigma\n",
    "            i += 1\n",
    "        print('training done.')\n",
    "        return self\n",
    "\n",
    "    # 定义最大熵模型预测函数\n",
    "    def predict(self, x):\n",
    "        res = np.zeros(len(x), dtype=np.int64)\n",
    "        for ix, x_ in enumerate(x):\n",
    "            tmp = self._pw(x_)\n",
    "            print(tmp, np.argmax(tmp), self.labels)\n",
    "            res[ix] = self.labels[self.y_[np.argmax(tmp)]]\n",
    "        return np.array([self.y_[ix] for ix in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(105, 4) (105,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "raw_data = load_iris()\n",
    "X, labels = raw_data.data, raw_data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=43)\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12580/713967991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmaxent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxEnt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmaxent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12580/562601513.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;31m# IIS算法步骤(3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# tmp = np.true_divide(self.EP_hat_f, self.EP_f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEP_hat_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_EP_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'method'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "maxent = MaxEnt()\n",
    "maxent.fit(X_train, y_train)\n",
    "y_pred = maxent.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
